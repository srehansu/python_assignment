{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87557b83",
   "metadata": {},
   "source": [
    "# 1. Data Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9c5d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64233746",
   "metadata": {},
   "source": [
    "# 2: Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d53b60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\SREHANSU\n",
      "[nltk_data]     BARIK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  one reviewers mentioned watching 1 oz episode ...  positive\n",
      "1  wonderful little production br br filming tech...  positive\n",
      "2  thought wonderful way spend time hot summer we...  positive\n",
      "3  basically theres family little boy jake thinks...  negative\n",
      "4  petter matteis love time money visually stunni...  positive\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean_review(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the review column\n",
    "data['review'] = data['review'].apply(clean_review)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0ac55",
   "metadata": {},
   "source": [
    "# 3: Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b0a145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the review text data\n",
    "X = tfidf.fit_transform(data['review'])\n",
    "\n",
    "# Display the shape of the transformed data\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b275fcd",
   "metadata": {},
   "source": [
    "# 4: Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "870ee03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d38652f",
   "metadata": {},
   "source": [
    "# 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2b0a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8878\n",
      "Precision: 0.8787468574743763\n",
      "Recall: 0.9017662234570352\n",
      "F1-score: 0.8901077375122429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred, pos_label='positive')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred, pos_label='positive')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred, pos_label='positive')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f380ea42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
